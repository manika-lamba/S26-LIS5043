<!DOCTYPE html>
<html lang="en"><head>
<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/tabby.min.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Dr.&nbsp;Manika Lamba">
  <title>Information Retrieval: Representations and Models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="styles.css">
  <link href="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Information Retrieval: Representations and Models</h1>
  <p class="subtitle">LIS 5043: Organization of Information</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Dr.&nbsp;Manika Lamba 
</div>
</div>
</div>

</section>
<section id="model-of-information-retrieval" class="slide level2 smaller">
<h2>Model of Information Retrieval</h2>

<img data-src="images/1.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><aside class="notes">
<p>This week, we’re going to talk about information retrieval (IR) from different perspectives. We’re first going to talk about the idea of representation within information systems, and how it affects information retrieval. Then we will look at some different information retrieval models that are present in today’s systems, as well as look at some of those in earlier systems.</p>
<p>To begin our discussion, here is the recap of the model from previous module to help you think through the idea of multiple representations and how they interact to connect users to information.</p>
<p>Representation A is the user’s information need, which the user enters into a system using terms that they believe represent this need.</p>
<p>Representation B is the representation created as a surrogate for the information object by a cataloger or indexer. Often the cataloger will use a set of authorized terms, called a controlled vocabulary to represent the subjects, but also a set of standards that tell them how to describe the object within the representation.</p>
<p>Both are entered into a system.</p>
<p>The retrieval component of the information system matches these two representations and brings back a subset of representations that the system contains that are representative of the words in the users queries. (We won’t go into the mechanics of searching at this point, or how the retrieval mechanisms work within various systems.)</p>
<p>The user then chooses a representation to review to see if it meets their information need or not.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="representation-definition" class="slide level2">
<h2>Representation: Definition</h2>
<ul>
<li><p>A system for choosing or highlighting some characteristics (attributes), together with a specification of the rules for selection (codes)</p></li>
<li><p>This implies a trade-off: if some characteristics are highlighted, other characteristics are left behind</p></li>
</ul>
<aside class="notes">
<p>Next, let’s begin by defining ‘representation’ within the broader context. Now you’ll recall, we talked about representation in previous. module, but let’s look even more specifically at some of the issues related to representation within IR systems.</p>
<p>Representation can be thought of as a system for choosing or highlighting some characteristics, or attributes – or general characteristics – together with the specification of the rules for selection and the code, meaning that we should understand a little bit about how the system is structured and how data exists within the system’s records.</p>
<p>This selection (or surrogation) process implies a trade - off of some kind. If some characteristics are highlighted, then we have to assume that other characteristics are left behind.</p>
<p>So, for example, in library catalogs we made decisions on what attributes of the information objects in our collection are important to describe in our records for users. In early catalog records these attributes included, Title, Author, Subject, and Classification.</p>
<p>In order to create those representations, the card catalog records, we had to decide which characteristics to highlight and which to leave behind.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="more-definitions" class="slide level2 smaller">
<h2>More Definitions</h2>
<ul>
<li><code>ENTITES</code>: objects or concepts</li>
<li><code>ATTRIBUTES</code>: characteristics of entities
<ul>
<li><code>DIACHRONIC</code>: stable across time</li>
<li><code>SYNCHRONIC</code>: changes across time</li>
</ul></li>
</ul>
<aside class="notes">
<p>Okay, let’s also look at some other definitions that we need to consider.</p>
<p>In terms of representations, we have to consider the term of ‘entities.’ Entities are those objects, or even concepts, that we’re going to represent.</p>
<p>‘Attributes’ are the general characteristics of information objects. So, we can also think of them as characteristics of the entities that we’re representing. There are different types of attributes; ‘diachronic’ and ‘synchronic’ attributes.</p>
<p>Diachronic attributes are those that remain stable across time. In other words, they do not change, and their meanings and uses also do not change.</p>
<p>And then there are synchronic attributes, and those are attributes that change across time. The change could be as simple as the use of a particular term or concept within a specific language.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="section" class="slide level2 smaller">
<h2></h2>

<img data-src="images/2.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><aside class="notes">
<p>On this slide I have modelled the idea of how <em>agency</em> plays a role in the information representation and retrieval process.</p>
<p>For example, we have an agency, which might be your local cataloging department, or it could be an indexing service within a database. That agency has a <em>document representation rule</em> , meaning that they have predefined the structure in that particular system . And then they’ve also made choices in terms of controlled vocabulary use, whether or not they use a controlled vocabulary or the specific one that they do use. And they may also have a <em>question representation rule</em> , meaning that a user has to input our question into the system using a specific format or syntax and it will be matched to the representations using a specific algorithm.</p>
<p>Also, part of this model is the <em>retrieval mechanism rule</em> . That particular system has a structure, such as the file structure or field structure. The retrieval mechanism rule would also include the types of data in the fields, how that data is retrieved, how it’s indexed within a system – whether or not a field is searchable, and then also the algorithms that match the user’s query terms to the representations (records) within the system.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="human-indexing" class="slide level2">
<h2>Human Indexing</h2>
<ul>
<li>Diachronic Attributes (do not change)
<ul>
<li><em>author, title, publisher, number of pages</em></li>
</ul></li>
<li>Only most general thought of users</li>
<li>Rules not evident to users</li>
<li><em>Great vagueness &amp; Generality resting on a foundation of shiftiing quicksand</em></li>
</ul>
<aside class="notes">
<p>There are several factors related to human indexing of particular documents within collections. As I’ve said, we have diachronic attributes, and those are the ones that don’t change. They’re always the same when representing something in the system. Examples of diachronic attributes would be author, title, publisher, number of pages.</p>
<p>The problem is that oftentimes representation systems have only the most general thought about users. We’re designing this system for retrieval, and the different agencies have different specifications for how or what they want to be retrievable within their system. But we’re oftentimes unaware of how the users use those particular systems or how they search for items within the systems. Another problem that comes in with human indexing is that the rules in which we create representations are not evident to our users. How many times have you used a library catalog, only to have results come back that are really confusing – with abbreviations you don’t understand or no information on how to access the resources?</p>
<p>So, again, there are different aspects of representation that are not evident to users or are confusing to users.</p>
<p>When we’re thinking about representation and the different factors from a human side that impact retrieval, “there’s a great vagueness and generality resting on a foundation of shifting quicksand.”</p>
<p>Because if you think back to the IR/representation model that we looked at earlier, users are only concerned with one side of the model; they’re concerned with how they enter their information need or their query into the system. As the person who is creating the representation, we have to be concerned with both sides. We have to know the rules for creating the representation, including the structure of the system, but we also have to understand how our users are interacting with and/ or searching within that particular system.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="requirements-for-successful-retrieval" class="slide level2">
<h2>Requirements for Successful Retrieval</h2>
<div class="r-stack">
<p><img data-src="images/3.png" class="fragment" width="250" height="250"></p>
<p><img data-src="images/4.png" class="fragment" width="500" height="400"></p>
<p><img data-src="images/5.png" class="fragment" width="600" height="400"></p>
<p><img data-src="images/6.png" class="fragment" width="700" height="500"></p>
<p><img data-src="images/7.png" class="fragment" width="750" height="500"></p>
<p><img data-src="images/8.png" class="fragment" width="800" height="500"></p>
</div>
<aside class="notes">
<p>Image 1: Okay, let’s look at some requirements for a successful retrieval. We have a collection. It is shown on this slide with these various different symbols, which may or may not be useful to us as a user. <code>(Click Next)</code></p>
<p>Image 2: Within our collection, there is at least one document, based on its representation that might be useful to us. <code>(Click Next)</code></p>
<p>Image 3: The user has some idea of what kind of information or information resource would be useful to them in helping to satisfy an information need. So, they input that information into the search mechanism of the information retrieval system with the hopes of enacting a match between their search terms and the terms used within the system to represent the objects on that particular topic, subject, or by a particular author.</p>
<p>So, we can say that retrieval was successful because at least one of the terms, the search terms that the user input into the system, matched with the terms in the representation and brought back the document or resource that the user thought might be useful. <code>(Click Next)</code></p>
<p>Image 4: So, we have a patron! <code>(Click Next)</code></p>
<p>Image 5: With a very specific information need. <code>(Click Next)</code></p>
<p>Image 6: When the indexer created this representation, they picked the four symbols that you see in the pink bar. And these symbols are represented within this document. Now, again, what they’ve done is chosen to <em>highlight</em> specific attributes of this object for their representation. So, we can see four different aspects that were probably more important topics within this object, and that’s what the cataloger/indexer chose to represent. Also, they might be constrained by their system parameters or local practice as to how many concepts they can represent instead of representing every concept within the document.</p>
<p>What’s also not known to the user at this point are the conventions (local practice rules in the cataloging department) and the different choices that the indexer must make.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/10.png" class="quarto-figure quarto-figure-center" style="width:80.0%;height:80.0%"></p>
</figure>
</div>
<aside class="notes">
<p>Part of the problem also is that the indexer and the patron often do not use the same code.</p>
<p>Or in this case, we can think of the controlled vocabulary, Library of Congress Subject Headings (LCSH), as the code that we use to represent subjects within our particular representations or records within our system.</p>
<p>Patrons in libraries do not usually have an understanding about what the four big, red books, or LCSH, contain and how they can be used in searching. And oftentimes, especially today in the automated world in which we live, we don’t provide the LSCH in online or print form to our users as a potential source of topics or search terms.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section>
<section id="section-2" class="title-slide slide level1 center">
<h1></h1>
<div class="columns">
<div class="column" style="width:60%;">
<p><code>Indexer has selected (perhaps among others) the concept that the patrons will want</code></p>
</div><div class="column" style="width:40%;">
<div class="r-stack">
<p><img data-src="images/11.png" class="fragment" width="250" height="250"></p>
<p><img data-src="images/12.jpeg" class="fragment" width="500" height="400"></p>
</div>
</div></div>
<aside class="notes">
<p>Image 1: It really becomes a bit of a guessing game for the indexer; they’ve selected, perhaps among others, the concept(s) that they think the patron will want or that the patron will use when they’re searching for documents about this particular item in the collection. <code>(Click Next)</code></p>
<p>Image 2: Now, if there’s a match between the terms or the concepts that this indexer or cataloger has chosen and the patron has used in their search terms, there is successful retrieval.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-if" class="slide level2">
<h2>What If?</h2>
<ul>
<li><code>Indexer picks a different topic</code></li>
<li><code>Indexer and patron use different terms for the same concept</code></li>
<li><code>Patrons cannot articulate just what the question state is</code></li>
</ul>
<aside class="notes">
<p>But! What happens if there’s no match? We can think about this as a dance.</p>
<p>So, what if the indexer picks a different topic?</p>
<p>What if the indexer and the patron use different terms for the same concept, such as if the indexer uses ‘automobiles’ and the patron uses ‘cars’ ?</p>
<p>What if the patron can’t articulate just what their question is or what their question state might be, meaning that they’re not entirely sure what kinds of information they’re looking for to satisfy this particular need.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-dance" class="slide level2">
<h2>The Dance</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Indexer</strong></p>
<p>describes doc</p>
<p>predicts use</p>
</div><div class="column" style="width:50%;">
<p><strong>Patron</strong></p>
<p>describes doc</p>
<p>predicts doc</p>
</div></div>
<aside class="notes">
<p>The dance begins between the indexer and the patron.</p>
<p>The indexer describes the document, where the patron is trying to predict the document that they need that will help them resolve an information need.</p>
<p>The indexer predicts use of the particular items that they’re representing.</p>
<p>The patron, on the other hand, has to somehow describe how they’re going to use the document or the object in your collection to satisfy their information need.</p>
<p>So, if you look at it from this perspective, you can see that there are a lot of places where the retrieval will break down. If the indexer and the patron do not correspond in terms of how the document is described and how they’ll use the documents or how the indexer believes the document will be used versus how the patron is describing their use, then there can be problems in retrieving documents from the collection.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="some-important-questions" class="slide level2">
<h2>Some Important Questions</h2>
<ul>
<li><code>What patron attributes can we know?</code></li>
<li><code>What document attributes can we know?</code></li>
<li><code>How can we use this knowledge to open the bottleneck between patrons in need and the documents that might be of use?</code></li>
</ul>
<aside class="notes">
<p>In previous module, we talked about users and what we can know about users. So, at this point, let’s also consider “What patron attributes can we know?</p>
<p>We can know about their age, we can know about their economic status potentially, depending on where they’re accessing our collection. We can know about their gender. We might know about the particular use. So, there are different aspects of patrons we can know about. Now that we’re in an online environment, knowing who our users are is very difficult, and our representations reflect that difficulty by becoming more general in nature.</p>
<p>We also can know what document attributes are useful within our systems. And how we determine this is oftentimes through user studies, in which we talk to users about how they use our systems, or how they use collections, or how they conduct searching within different systems.</p>
<p>So, how can we use this knowledge to open up what we would consider the ‘bottleneck’ between patrons with a particular information need and the documents that might be of use to them?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="indexing-factors-affecting-ir-performance" class="slide level2 smaller">
<h2>Indexing Factors Affecting IR Performance</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ol type="1">
<li><span style="color: orange;">Indexing</span></li>
</ol>
<hr>
<ol start="2" type="1">
<li><span style="color: purple;">Type of Knowledge</span></li>
</ol>
<hr>
<ol start="3" type="1">
<li><span style="color: red;">Effective/Cognitive</span></li>
</ol>
</div><div class="column" style="width:50%;">
<p>1.1 <span style="color: orange;">Consistency</span></p>
<p>1.2 <span style="color: orange;">Subject Expertise</span></p>
<p>1.3 <span style="color: orange;">Indexing Expertise</span></p>
<hr>
<p>2.1 <span style="color: purple;">Searching Experience</span></p>
<p>2.2 <span style="color: purple;">Domain Knowledge</span></p>
<hr>
<p>3.1 <span style="color: red;">Motivation Level</span></p>
<p>3.2 <span style="color: red;">Emotional State</span></p>
</div></div>
<aside class="notes">
<p>There are other indexing factors that do effect information retrieval (IR) performance, and some of these are related back to human factors.</p>
<p>For example, within the indexing process and resulting index , there is a problem that we call ‘inter - indexer consistency,’ or ‘inter - indexer inconsistency,’ meaning that there is a low percentage of consistency between any two indexers when they’re creating representations.</p>
<p>There is also the problem with subject expertise. People with higher domain knowledge, generally, are better indexers in that particular area.</p>
<p>And also indexers with more experience tend to know the codes or the controlled vocabularies better, as well as how representations are structured.</p>
<p>Then there are also factors from the user’s side such as the types and levels of knowledge, the user’s search experience and domain knowledge; these factors can also play a role in retrieval performance.</p>
<p>There are also effective and cognitive factors, such as a person’s motivation level and emotional state as they’re looking for information.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="other-factors-to-consider" class="slide level2">
<h2>Other Factors to Consider</h2>
<ul>
<li><code>Use of Standards/Rules (code)</code>
<ul>
<li>Depends on form of index/abstract</li>
<li>Depends on criteria of employer
<ul>
<li>Pages allocated</li>
<li>Format used</li>
<li>Order</li>
</ul></li>
</ul></li>
<li><code>Depends on Resources/Audience</code></li>
</ul>
<aside class="notes">
<p>One final set of factors to consider – and I’m sure that you can also think of others – is that the indexer or cataloger has specific standards and rules, or what we might refer to as a code, that have to be followed when they create representations.</p>
<p>We’ll be covering the codes or standards we use in library cataloging or indexing in more depth coming in future modules. Those standards and rules depend on the form of the index or the abstract or the record being created; they also depend on criteria of employers, such as how many pages are allocated for an index, what format can be used, how will the information be structured and displayed to the users, what is the particular order of the elements of the record, etc.</p>
<p>Again, all of this depends upon which type of organizing structure is being developed (MARC record, back of the book index, etc.), as well as the audience or the users.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="information-retrieval" class="slide level2 smaller">
<h2>Information Retrieval</h2>
<blockquote>
<p><code>A process in which sets of records or documents are searched to find items which may help to satisfy the information need</code></p>
</blockquote>
<ul>
<li><p>IR is concerned with:</p>
<ul>
<li><code>representation</code></li>
<li><code>storage</code></li>
<li><code>organization</code></li>
<li><code>accessing of information objects</code></li>
</ul></li>
</ul>
<aside class="notes">
<p>Okay, now that we have talked a little bit about representation and some of the issues related to representation within IR systems, let’s step back a bit and talk about IR, as well as IR models.</p>
<p>IR has been defined very basically as a process in which sets of records or documents are searched to find items, which may help to satisfy the user’s information needs.</p>
<p>Now, we know from our discussions throughout class that IR is a lot more complicated than has been defined here.</p>
<p>IR is concerned with several different processes as well as how the system is structured. It’s concerned with</p>
<ul>
<li>representation from both a user’s side, or</li>
<li>how the user represents their need within a system mechanism, and from the computerized side, or</li>
<li>from the system’s side of how items in the collection are represented within the system,</li>
<li>how the system is set up and structured, and</li>
<li>how the cataloger or indexer has represented those objects within that system structure.</li>
</ul>
<p>IR is also concerned with storage of the representations from the system side (and how the system is structured) and the organization of those representations, meaning how the field structure is devised, the system search algorithms, and the different IR models in use to access the information objects successfully.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="information-retrieval-cont." class="slide level2 smaller">
<h2>Information Retrieval (Cont.)</h2>
<ul>
<li>Information retrieval concerns a range of concepts
<ul>
<li><code>User Group</code>
<ul>
<li>types of knowledge</li>
<li>context &amp; information environment</li>
</ul></li>
<li><code>Information Need</code></li>
<li><code>Information Sources</code></li>
<li><code>Information System</code>
<ul>
<li>system capabilities/IR techniques used</li>
<li>how information organized</li>
</ul></li>
<li><code>Results of the Query</code></li>
<li><code>User Selection &amp; Evaluation (Relevance)</code></li>
</ul></li>
</ul>
<aside class="notes">
<p>IR concerns a wide range of concepts. In last module, we talked about users, what we have learned about users in our research, and what we can learn about users – related to their types and levels of knowledge – as well as the different variables the come into play that are related to context and the information environment in which they’re conducting their searches. We also talked about different information needs and information sources.</p>
<p>We’re going to focus this time more about the <strong>information system</strong>. We are going to look at the system capabilities and the IR techniques or models being used, as well as how that impacts how information is organized and retrieved. Another component here, of course, is the results of the query and the user selection.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="information-retrieval-cont.-1" class="slide level2 smaller">
<h2>Information Retrieval (Cont.)</h2>
<ul>
<li>The central problem of IR is how to represent documents for retrieval</li>
<li>To be more successful, document representation must be used in ways similar to the ways ordinary language is used
<ul>
<li>document representations should take context into account</li>
<li>document representations should take users into account</li>
</ul></li>
</ul>
<aside class="notes">
<p>The central problem of IR then is how to represent documents for retrieval. Our field has done a lot of research on users and their information behavior, as we talked about in the last module. We can also think about it from the system’s side of how documents are represented by human agencies as well as computerized agency within the system.</p>
<p>To be more successful, we’ve found in our research, document representation must be similar to the way that ordinary language is used, which, again, presents some problems.</p>
<p>We’ll talk later in this lecture about the natural language processing model of IR and some of the issues associated with that.</p>
<p>But document representation should take context into account, or the domain of the system into account, as well as the users of that system.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="information-retrieval-cont.-2" class="slide level2 smaller">
<h2>Information Retrieval (Cont.)</h2>
<ul>
<li><code>Most IR is based on techniques introduced in the 1960's</code>
<ul>
<li>Primarily text-based retrieval</li>
<li>Makes use of inverted indexes and index terms</li>
</ul></li>
<li><code>IR is no longer just a library problem</code>
<ul>
<li>Used in businesses, everyday settings</li>
<li>Used in search engines</li>
</ul></li>
<li><code>As a result of these evolved uses high standards of retrieval are expected by users</code></li>
</ul>
<aside class="notes">
<p>IR and the models that we’ll cover in this lecture, both the classical and the more advanced models being developed and being used today, were introduced in the 1960’s. The retrieval within those models was and still remains primarily textual based. What I mean by ‘textual based’ is that the systems were being designed primarily to retrieve text - based documents within sets of different document collections using text - based representations.</p>
<p>IR systems also make use of inverted indexes and index terms, especially within our online databases. Even search engines have inverted indexes as the basis for retrieval.</p>
<p>It’s also important to note that information retrieval is no longer just a library problem. People do not just retrieve documents within library systems any longer; IR is used in multiple different contexts as well as in everyday homes. People are using the web, and the penetration of web access within the home environment is pretty high within the United States, though it does vary. There are definitely digital divide issues; however, users can also access the web for everyday use in libraries and other organizations, and of course, using smart phones and other devices. And around the world we know that access to the web is also at varying levels.</p>
<p>As a result of these more evolved uses – we’re no longer just using databases to do research – users have very high standards of retrieval and of our retrieval systems. And oftentimes they come away from a library OPAC being very unsatisfied with the results. Some of these expectations can be attributed to the system, but also to the user’s misunderstandings about how that particular system functions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="taxonomy-of-ir-techniques" class="slide level2">
<h2>Taxonomy of IR Techniques</h2>
<ul>
<li><code>We can divide IR techniques into basic classes</code>
<ul>
<li><strong>Exact Match</strong>: <em>where the set of retrieved documents contains only documents whose representations match exactly with the query</em></li>
<li><strong>Partial Match</strong>: <em>where there is some matching that occurs, but it is not exact, although some of the documents may be exact matches to the query</em></li>
</ul></li>
</ul>
<aside class="notes">
<p>At the heart, we can divide information retrieval techniques into two basic classes: <strong>exact match</strong> and <strong>partial match</strong>. Systems today still have these techniques in place.</p>
<p>Exact match is where the set of retrieved documents, contains <em>only</em> documents whose representations – those of the indexer within the system and those of the user in their search queries – <em>match</em> exactly when an IR transaction is taking place.</p>
<p>For example, in an exact match system, if I put in the terms, ‘information’ and ‘data,’ my system documents are only going to retrieve those items that include ‘information’ and ‘data,’ and they will leave out any other types of materials that might be related even though they could be potential matches.</p>
<p>In a partial match model, this is where some matching occurs, the terms are not necessarily exactly the same, some of the documents may be exact matches to the query, but then others might be what we considered ‘partial’ or ‘low relevance matching.’ Both of these two techniques are still present in systems today.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="traditional-ir-model" class="slide level2 smaller">
<h2>Traditional IR Model</h2>
<h4 id="simple-match-model"><strong><code>Simple Match Model</code></strong></h4>
<blockquote>
<p><strong>Request = Information Data</strong></p>
</blockquote>
<p>Document A = data, information</p>
<p>Document B = data, information</p>
<p>Document C = information, retrieval</p>
<p><code>Advantages</code>: simple process; widespread; familiar</p>
<p><code>Disadvantages</code>: single descriptor requests less effective in large databases</p>
<aside class="notes">
<p>One of the classical IR models is the <em>‘simple match model’</em> or a <em>‘best match model’</em> that is part of an IR model.</p>
<p>For example, the user has a request, which is the information that’s needed, and that matches to the documents in our collection. So, again if we use that same example of ‘data’ and ‘information,’ if document A and document B have some reference to ‘data’ and ‘information’ within that system’s representation, within their index record, or within their bibliographic record, then we’re going to have a successful match.</p>
<p>The problem with simple match models is that it usually uses only a few query terms which becomes less effective in large databases.</p>
<p>The advantage is that it’s a simple process; it’s very wide spread and familiar to our users. They enter terms into a search engine or into a fielded search in a database, and they get back results.</p>
<p>But as I said, it becomes even less effective in larger databases where we’re searching multiple collections with thousands of documents within the collections.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="boolean-ir-model" class="slide level2 smaller">
<h2>Boolean IR Model</h2>
<ul>
<li>Boolean Retrieval
<ul>
<li>one step above the basic model</li>
</ul></li>
<li>Named after the creator, <em>George Boole</em>, of Boolean algebra, around 1850</li>
<li>Most familiar IR technique used in OPAC’s and online databases</li>
<li>Uses <code>AND</code>, <code>OR</code>, and <code>NOT</code> to allow more complex queries to the IR system</li>
<li>Works with that what is called <code>Set Theory</code></li>
</ul>
<aside class="notes">
<p>One of the most <em>prevalent</em> classical IR models is what’s called ‘Boolean retrieval,’ which is one step above the basic model that I just described.</p>
<p>Boolean retrieval is present in most systems today that you’ve used, from library OPACs, to databases, to search engines. ‘Boolean’ was named for its creator, George Boole, when he developed Boolean algebra around 1850.</p>
<p>As I noted, it’s probably the most familiar IR technique, but it’s also one of the least understood techniques because the user has to manipulate the query in some way, where other techniques might work behind the interface and the user doesn’t have as much control over how the query is processed by the system, but they also don’t know what the system is doing.</p>
<p>Boolean uses the AND, OR, or NOT operators to allow more complex queries within the system. A user can structure queries in many different ways, and systems may also process Boolean operators in a different order, meaning that those search operators of AND, OR, or NOT are treated in a specific order within that system.</p>
<p>We’ll talk more about operator order and Boolean searching in the next lecture, when we look at specific search structures and creating good search strings within IR systems.</p>
<p>Boolean also works with what is called ‘set theory,’ which is a binary approach – an item either belongs to a set or it doesn’t belong to a set. This is both an advantage and a limitation of the IR model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="boolean-ir-model-cont." class="slide level2 smaller">
<h2>Boolean IR Model (Cont.)</h2>
<ul>
<li><p>Example of Boolean Search</p>
<p><img data-src="images/clipboard-953469533.png"></p></li>
</ul>
<aside class="notes">
<p>Let’s take a look at an example of a Boolean search. We’re going to use as our search ’information AND retrieval NOT data.</p>
<p>AND in a Boolean search serves as an intersection between the terms, meaning that any documents that are retrieved have to include both ‘information’ and ‘retrieval,’ otherwise the result set will not include that particular document. The OR serves as a union, meaning that any of the two terms have to be present within the document within the OR relationship or the document would not be returned in the retrieval set.</p>
<p>The NOT serves as a complement, or we might think of it as a way of filtering out those documents that we do not want to see retrieved.</p>
<p>So, in this particular search we have ‘information AND retrieval NOT data.’ In document A, we have ‘information’ and ‘data.’ So, with the NOT serving as a complement or a filtering function, document A would not be retrieved.</p>
<p>Document B includes ‘information’ and ‘retrieval,’ which satisfies our first criteria, and ‘IR.’ Now, we don’t have the concept of IR as stated as the acronym as part of our retrieval, but because this document includes our two terms, ‘information’ and ‘retrieval,’ and it does not include the term ‘data,’ this document would be retrieved. Document C ‘information’ and ‘data’ and ‘retrieval’ would, again, not be retrieved because it includes the term ‘data.’</p>
<p>And then, in Document D ‘information’ and ‘retrieval’ and ‘book’ would be returned because it includes our terms ‘information’ AND ’retrieval.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="problems-with-boolean-model" class="slide level2">
<h2>Problems with Boolean Model</h2>
<ul>
<li>Need to know the order (preference) the operators are processed by the system</li>
<li>Seems very simple to users but is really fairly complex</li>
<li>May miss potentially relevant documents</li>
<li>Does not rank retrieved documents</li>
<li>Concepts within documents are difficult to show</li>
<li>So why do we continue to use them?</li>
</ul>
<aside class="notes">
<p>There are of course some problems with the Boolean model.</p>
<p>One of which is that you need to know the order in which those operators are processed by the system.</p>
<p>Depending upon the information retrieval system, some will use the AND operator relationship first, and then they will process the OR, followed by the NOT. Others have as first preference the OR, followed by AND, and then NOT. Depending upon how you construct your query and the order of operation, you can have some very interesting results as an impact of how the system processes those Boolean operators.</p>
<p>Also, Boolean seems very simple to users, but as you saw, there were three types of relationships that are constructed in Boolean statements, and queries can really become very complex. People also misunderstand how OR or AND function within Boolean systems.</p>
<p>A searcher may miss potentially relevant documents by using the NOT operator. If you filter out an entire set of documents based on particular terms, you’re then probably missing documents that might be useful. So, a cautionary note is to use NOT very sparingly, or to start without NOT in your statement and then you can use it later to filter out larger sets of documents.</p>
<p>Boolean retrieval also does not rank documents, so all of the terms within the document are treated at an equal level, which in some cases may be appropriate and others, not. We’ll talk more about weighted retrieval in a few minutes.</p>
<p>Concepts themselves as opposed to words are difficult to represent within the Boolean IR model, but if you use very advanced search techniques, such as nesting with Boolean operators–we can get closer to representation of concepts.</p>
<p>The last thing that I wanted to mention about Boolean is with all of these difficulties, we continue to use this model because it has been part of our IR systems for many years, and it’s a very effective way of retrieving documents even with these different potential issues that I’ve just mentioned. And our users do like to use Boolean in the sense that they like to have more options in their retrieval. But we do have new models in current environments that allow better retrieval but with less control over what the system is doing or how it’s processing your terms.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="term-weighting" class="slide level2 smaller">
<h2>Term Weighting</h2>
<ul>
<li><code>Weighted IR (probabilistic IR)</code>
<ul>
<li>makes use of inverted index and index terms</li>
<li>easier to assign weights if automatically indexed</li>
<li>each term in the index has a weight or value attached to it
<ul>
<li>weight reflects its relative importance in the document</li>
</ul></li>
<li>weight is determined by use of term frequency
<ul>
<li>defined as the number of occurrences of a term in the document</li>
<li>more frequently a term appears in a document, the more likely it is to an important concept within the document</li>
</ul></li>
</ul></li>
</ul>
<aside class="notes">
<p>Weighted information retrieval, what is oftentimes referred to probabilistic information retrieval, is another classical IR model that we’re going to talk briefly about.</p>
<p>Weighted IR is usually in systems that have inverted indexes and index terms because what the system needs to do is have a set of terms to which it assigns weights, and it assigns weights based on the value of the word or the term within the document. So, what the system does is assign a weight to each term within the inverted index, and then within the searching process, the higher weighted documents or terms are retrieved. The weight is supposed to reflect the relative importance of a term within the document.</p>
<p>There are different schemes that are used for weighting. The most frequently used is what’s called ‘term frequency’ or ‘co-occurrence’ within a document. Basically, when we think about term frequency, it’s the number of occurrences of a term within a document, or how often a particular word appears within that document. We also can weight documents within sets. A system can examine how frequently a term occurs within the documents of a particular set. We also can look at term co-occurrence, as I mentioned, or how frequently the term appears within a document, but also in co-occurrence or in proximity to additional important or higher-weighted terms.</p>
<p>The assumption behind a weighted system then, is that the more frequently a term appears in a document, the more likely that term is to be an important concept within the document, or that it represents the overall topics being discussed within the document. One problem with this, however, is if a term is used too much within a document or the terms are used too much within the document set, or within the database system, the term becomes un-useful. We call this distinctiveness within databases; for example, if we’re searching within a system that’s filled with computer-related documents, and this is a computer science database, the term ‘computer’ is of low value in both the indexing and retrieval processes because if every document in the set is related to computers, when you do a search with the term ‘computers,’ you’re going to return every single document in the collection. So, even though weighting can be really useful, you also have to take the context or the domain into account when you’re both selecting index terms as well as when you’re selecting terms for your retrieval.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="example-of-weighted-ir" class="slide level2">
<h2>Example of Weighted IR</h2>

<img data-src="images/clipboard-4050955481.png" class="r-stretch"><aside class="notes">
<p>Let’s take a look at an example of weighted IR.</p>
<p>The topic of the document is ‘information’ and ‘data retrieval.’ Some of the terms in the index might include ‘information retrieval,’ ‘data,’ ‘retrieval,’ ‘information,’ ‘system,’ ‘index,’ and ‘representation,’ and you can see from this example that this inverted index has both word and phrase indexing as possible within its structure.</p>
<p>The column on the right hand side seems to have some extraneous words, such as ‘book,’ ‘illusion,’ ‘yellow,’ ‘car,’ ‘green,’ ‘ball,’ and ‘keys.’</p>
<p>In a weighted information retrieval model, within this particular document, the terms in the left hand column are probably more frequently used within the document, and the terms in the right hand column are probably used as examples or illustrations, and they would probably have lower weights assigned.</p>
<p>How that would impact retrieval then is if you do a search for ‘information retrieval’ or ‘information AND data,’ ‘data retrieval,’ ‘system’ or ‘representation,’ you’re probably going to retrieve this document because it would have higher weights for those terms.</p>
<p>If you’re doing a search for ‘book,’ or ‘yellow’ or ‘car’ within this particular system, you’re probably not going to retrieve this document because those terms would have lower weights assigned to them.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="term-weighting-cont." class="slide level2 smaller">
<h2>Term Weighting (Cont.)</h2>

<img data-src="images/clipboard-1263592877.png" class="r-stretch"><aside class="notes">
<p>There are, of course, advantages and disadvantages to the term weighting model. The advantage is that it speeds up access because those lower weighted terms are not searched, nor are they retrieved for a user. Generally, it gives a user a smaller set of documents to evaluate.</p>
<p>The problem, however, is that often it is not known what weights are based on, or what the system algorithms deem as important in the weighting scale of a document. The weights are based on the system designer’s criteria; the weights are based on that particular algorithm within the system. And those weights could be wrong, or within particular documents the weights might be wrong, or the user may think that those documents are relevant, but if the lower weighted documents are missing from their set, the user may potentially miss documents that are partially useful to their information need.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="other-ir-models" class="slide level2">
<h2>Other IR Models</h2>
<p><img data-src="images/clipboard-588880613.png"></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://www.osti.gov/servlets/purl/1055624#page=1.00&amp;gsr=0"><img data-src="images/clipboard-3169439169.png" class="quarto-figure quarto-figure-center" width="515"></a></p>
</figure>
</div>
<aside class="notes">
<p>There are other information retrieval models, such as vector space modeling, or what has been known now more recently as ‘clustering,’ Vector space modeling is one of the classical models that has been in development since the 1960s. Vector space modeling or clustering is a partial match technique, meaning that as long as part of your term is present within the document or within the document’s indexing, the document will be retrieved. It uses a weighted scheme, so the terms within the document are given weights, and what differs in a vector space model is that the queries terms are also given weights. So, documents within those sets or those clusters are ranked in decreasing order of the similarity to the query.</p>
<p>What is nice about vector space models, or ‘VIRI’s,’ as we would call a visual information retrieval interface using the vector space model, is that both the document and the query are represented as term vectors, or points on the diagram, and then the user can manipulate how close they want those vectors to coincide. The term vectors for both the document and the query are then compared for similarity.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="clustering-such-as-faceted-search-tag-clouds" class="slide level2 smaller">
<h2>Clustering (such as faceted search, tag clouds)</h2>

<img data-src="images/13.png" width="336" class="r-stretch"><aside class="notes">
<p>There are not really any commercial systems that give the user all the features of the vector space model, though there are a lot of experimental systems that use this IR method. However, you can think of the social networking and the socially constructed information, such as tag clouds, as a clustering mechanism as well, but it’s more of a user-generated content system than one that’s being generated by the computer.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="clustering-cont." class="slide level2">
<h2>Clustering (Cont.)</h2>

<img data-src="images/clipboard-3182139681.png" class="quarto-figure quarto-figure-center r-stretch" style="width:30.0%"><aside class="notes">
<p>So, to explain this further, you have a set of documents that are related to a specific topic, such as how to set up a habitat for lizards. In the system all of the documents in the collection on the topic of lizards are in one cluster. When the query is presented to the system, it only searches within the relevant cluster or within the vector space that’s related to that particular topic. So, those term vectors are compared for similarity. As long as the documents within each cluster accurately represent the subject of the information objects, then the search will be successful.</p>
<p>There are some search engines, for example Clusty, that use clustering as its retrieval mechanism.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="topic-modeling-clustering-approach" class="slide level2 smaller">
<h2>Topic Modeling: Clustering Approach</h2>
<ul>
<li><p>Topic modeling itself is a <em>soft</em> clustering method but the output of topic modeling can be used for classification in downstream tasks such as information retrieval and improving recommendation systems</p></li>
<li><p>It is used to infer the hidden themes in a collection of documents and thus provides an automatic means to organize, understand and summarize large collections of textual information</p></li>
<li><p>It is based on statistical and machine learning techniques to mine meaningful information from a vast corpus of unstructured data and is used to mine document’s content</p></li>
<li><p>It infers abstract topics based on <strong><em>“similar patterns of word usage in each document”</em></strong>. These topics are simply groups of words from the collection of documents that represents the information in the collection in the best way</p>
<p><img data-src="images/clipboard-1809129871.png" width="500"></p></li>
</ul>
<aside class="notes">
<p>Read slides</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="other-ir-models-1" class="slide level2 smaller">
<h2>Other IR Models</h2>
<ul>
<li><code>Semantic or Linguistic Model</code></li>
</ul>
<blockquote>
<p>attempts to get at the “concepts” contained in the information object or the surrogate</p>
</blockquote>
<ul>
<li><p>syntactic analysis</p></li>
<li><p>free text searching</p></li>
<li><p>paragraph indexing</p></li>
<li><p>discourse analysis</p></li>
<li><p>Passage Retrieval</p></li>
</ul>
<aside class="notes">
<p>There are other IR models that were developed beginning in the sixties, but they really came into fruition in the nineties and in 2000s. One of these is are the semantic or linguistic model.</p>
<p>It’s a really complicated model. An example of systems that are using such model is Ask.com, the search engine. For the most part, it’s not used in a lot of commercial systems because it uses a lot of computing power, though that isn’t as much of an issue as it used to be, but it’s also subject to the foibles of human language.</p>
<p>Semantic or linguistic models attempt to get at the concept levels, rather than the word levels, contained in the information documents or their surrogates. It is accomplished at various different levels depending on the system. Some systems using natural langauge model (NLP) do a syntactic analysis, where the system is looking at the meaning, or trying to extract the meaning of sentences, or even at the paragraph level if they’re doing paragraph indexing. Also, the system may be using a discourse analysis level, where the algorithm is looking at whole passages and trying to discern meaning and then matching queries with their semantic algorithms.</p>
<p>Free text searching and full text searching also have elements of NLP associated with it, but again, NLP is not part of many commercial systems because it does require a lot of computer power to make it work, but it also is really dependent on human language and the language within documents. So, NLP systems tend to be within more subject-specific databases rather than, say, on the web. If they’re used on the web, such as in Ask.com, it’s usually for more factual kinds of questions, and their data sets tend to be more subject-specific as opposed to being able to search everything like you can with Google.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="newer-ir-models" class="slide level2 smaller">
<h2>Newer IR Models</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li><p>User Profiles</p>
<ul>
<li>uses heuristics (rules of thumb)</li>
<li>uses process models</li>
</ul></li>
<li><p>Intelligent Agents (e.g.&nbsp;Windows Cortana)</p>
<ul>
<li>autonomous</li>
<li>able to learn</li>
<li>customizable</li>
</ul></li>
<li><p>Web Search Engines</p></li>
<li><p>Data Mining/Text Extraction Methods</p></li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/clipboard-1471905613.png"></p>
<figcaption>Example of Conversational Retrieval System</figcaption>
</figure>
</div>
</div></div>
<aside class="notes">
<p>There are also some other, newer IR models that emerged in the 70s, and now in the 90s with the web, and even in 2000s with the use of, for example, user profiles that we see in Bing. Bing tracks what its users do and assembles profiles based upon the heuristics of the user searching and the whole search process when they’re using the Bing search engine. So, it uses what are called heuristics, or rules of thumb, basic rules that are present in the majority of search experiences. Bing also uses what are called process models, where the search engine looks at the entire process and tries to develop generic process models for users within the Web environment.</p>
<p>Also coming out of the seventies and eighties is the idea of intelligent agents. These were, and still are, little software programs that are supposed to be autonomous. They are able to watch and learn what a user does when they’re searching or they’re using different database systems, and then they customize the system or help give the use helpful advice whenever they come to that particular system to do a search.</p>
<p>Microsoft had an experiment with intelligent agents, with their ‘Bob’ search and software user interface, which was probably about in ’93 and ’94. You used to have that little paperclip that would pop up all the time and tell you, “Would you like to do this?” or “I can help you do this.” Bob was kind of similar to that, but Bob was a person, an agent, as opposed to a paperclip.</p>
<p>But it’s, again, an idea. It’s a newer IR model than those classic models that we talked about, and it’s something that we do continue to still explore. Cortana in Windows 10 systems is an intelligent agent. Systems like Amazon’s Alexa use both user profiles and intelligent agents to develop a profile of the users of each Alexa device.</p>
<p>Web search engines, of course, we’re all familiar with now, have really only been around since about 1993 when the World Wide Web graphical user interfaces were developed in Mosaic and in early Netscape. But web search engines, of course, are something people use every day. Web search engines don’t necessarily all work the same way. As I said, Bing has a different mechanism for searching than Google does.</p>
<p>We also have what’s called data mining, text extraction, machine learning, knowledge representation models. A lot of data mining and text extraction are based upon term frequency counts and extracting and assigning weights to terms within documents, but then also it re-purposes documents and pulls them together in very dynamic ways based upon the parameters you set for these particular processes. So, within a data mining environment, we might tell the system that we need to find all the documents on a particular topic and it will extract them based upon the algorithms that have been set up in the system. Text extraction works in a similar manner; it’s really a way that we can analyze at a word level what’s in document. And we also use data mining and text extraction in some NLP systems as well to discern contextual patterns in the data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="retrieval-augmented-generation-rag" class="slide level2 smaller">
<h2>Retrieval-Augmented Generation (RAG)</h2>
<p><code>Retrieval-Augmented Generation (RAG) = Information Retrieval (IR) + Large Language Models (LLMs)</code></p>
<p>RAG is a technique that helps AI models generate better, more <strong>accurate, and up-to-date</strong> responses by <strong>retrieving relevant information</strong> from external sources before generating an answer</p>
<p><code>Why Do We Need RAG?</code></p>
<p>Traditional <strong>LLMs (like GPT-4)</strong> have a <strong>fixed knowledge base</strong> from training data. But:<br>
- They <strong>don’t know new information</strong> after training.<br>
- They <strong>hallucinate</strong> (make up facts).<br>
- They <strong>struggle with specific or niche knowledge</strong> (e.g., latest research papers).</p>
<ul>
<li><strong>Solution: RAG helps by searching for relevant documents and using them to generate accurate answers!</strong></li>
</ul>
<aside class="notes">
<p>With the recent advancement in generative AI, we can use large language models for information retrieval.</p>
<p>LLMs are trained on massive datasets, but once training stops, their knowledge is frozen in time. So, if something happens after their last update, like a new scientific discovery, they have no idea about it and they start hallucinating.</p>
<p>Hallucination is defined as when a model generates something that sounds convincing but isn’t actually true. This is a big problem in applications like medicine or law, where accuracy is crucial.</p>
<p>So, how do we fix these issues? That’s where RAG comes in!</p>
<p>Instead of just relying on pre-trained knowledge, a RAG model first retrieves relevant information from an external source—like a database, Wikipedia, or even real-time web searches—and then generates a response using that data.</p>
<p>This means RAG models are:</p>
<ul>
<li><p>More up-to-date: Because they pull in fresh, external knowledge.</p></li>
<li><p>More accurate: Since they ground their responses in retrieved facts.</p></li>
<li><p>Less prone to hallucination: Because they verify information before generating text.</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-does-rag-work" class="slide level2">
<h2>How Does RAG Work?</h2>
<p><strong>Imagine you ask an AI:</strong></p>
<p>🗣️ <em>“Who won the Nobel Prize in Physics this year?”</em></p>
<p><strong>Without RAG (LLM Only):</strong></p>
<p>🤖 <em>“I don’t know. My training data only goes up to 2023.”</em></p>
<p><strong>With RAG (LLM + IR):</strong></p>
<p>🤖 <em>(Searches the web → Finds latest Nobel Prize winners → Summarizes the results)</em></p>
<p><em>“The 2024 Nobel Prize in Physics was awarded to [Winner’s Name] for [Reason].”</em></p>
<aside class="notes">
<p>This slide an example of searching information using RAG.</p>
<p>But RAG is still not perfect. The biggest challenges are:</p>
<ol type="1">
<li><p><strong>Retrieval quality</strong>: If the system fetches bad or irrelevant information, the response will also be wrong.</p></li>
<li><p><strong>Latency</strong>: Searching external sources takes time, which slows down response generation.</p></li>
<li><p><strong>Security &amp; Privacy</strong>: Some sources might not be reliable, or the model could pull sensitive data.</p></li>
</ol>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ir-systems-you-use" class="slide level2">
<h2>IR systems You Use</h2>
<ul>
<li><p>Online catalogs</p></li>
<li><p>Online databases</p></li>
<li><p>Web Search Engines</p></li>
</ul>
<aside class="notes">
<p>There are a lot of different information retrieval systems that you as a user encounter every day: library online catalogs, online databases, such as OU Libraries database, but there are also databases on the web that you use and that are being used without you even knowing it–say, for example, Google Scholar is a database,–and of course, your search engines within the web. There’s a really good resource that you might at some point take a look at. It’s a little complicated because it’s trying to be everything to every type of user.</p>
<p>And that’s the Search Engine Watch page–<a href="https://searchenginewatch.com/" class="uri">https://searchenginewatch.com/</a>. It has news about what’s going on in search engine development, it talks about the mechanics of search engines and search engine optimization, etc. Social media sites are also an example of a system you may use.</p>
<p>As you use different IR systems every day, think about</p>
<ul>
<li><p>How these different systems employ different IR methods and models?</p></li>
<li><p>How is the system structured?</p></li>
<li><p>What aspects of the system are hidden from the user?</p></li>
</ul>
<p>Try to determine the structure of the system and how you retrieve information by examining the interface features, such as a drop down options or field lists in an online database, or features designed to enable fielded searching in your online catalogs. For example, what fields are searchable? Can you conduct Boolean searches?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-does-this-relate-to-searching" class="slide level2">
<h2>How Does this Relate to Searching?</h2>

<img data-src="images/clipboard-158779916.png" class="r-stretch"><aside class="notes">
<p>Now that you have a basic introduction to information retrieval and some of the models that help in retrieval in different systems, let’s talk about how this relates to searching. It’s important that we understand how our different systems are structured and also what model of retrieval is running the algorithms behind the scenes or behind the interface, if you will. The organization of the record within the file is what holds the key as well as those algorithms.</p>
<p>In earlier systems, our methods for finding the location of the record and for matching representations from the user, their search terms, and representations within the records was a sequential search of all the records in a file, and as you can imagine, this took a great deal of time. Most of our systems nowadays use either an inverted index file, which is an individual index for every field that is searchable within our system or they use keyword searching. In some of the newer systems, we might even have full text searching.</p>
<p>So, there are different ways in which you can enact a query, but the system is generally searching an inverted index of those fields that have been deemed searchable. Within bibliographic records, especially those that have OPACs, we often have multiple indexes which provide searchable fields for our users.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="cautions" class="slide level2">
<h2>Cautions</h2>
<ul>
<li>We should take a more global view of IR</li>
<li>Users (including information professionals) need to know which IR model or technique the system is using for retrieval</li>
<li>Users also need to know how information systems are structured and how objects are represented in the system</li>
</ul>
<aside class="notes">
<p>I want to mention just a few cautions when we’re thinking about information retrieval and information retrieval models. When we designed these systems, we were designing the models and the systems for local use. We didn’t have the networked connections that we have presently; we didn’t have the World Wide Web back in the sixties; so, we were designing systems that could be used in a local context.</p>
<p>So, at this point, we really need to take more of a global perspective when we’re thinking about information retrieval. If we’re designing a system or we’re creating representations, we need to think about the global community that might be accessing this system.</p>
<p>We also as users, and this includes information professionals, need to know which information model or technique the system is using for retrieval. What I mean here is that whenever you start using a database, it will save you a lot of time and effort if you familiarize yourself first with the different search functionalities that you have, if you can get a sense of the IR model that’s being used, and you can look for some of those more advanced search filters or functions, such as stemming and proximity searching, that might be present within that system.</p>
<p>Also try to find out if it has a thesaurus function where you can have access as a searcher to the controlled vocabulary used by the system for its indexing. Using the thesaurus feature, if applicable in that system, will make your searching more precise to begin with.</p>
<p>Users also need to know how information systems are structured, what the field structure is, what the indexing system is, and how their objects are represented within the system, which fields are searchable, if there is an inverted index that is being searched, is it both word and phrase searched, or indexed. Each of these elements of system structure are going to impact how you’re going to conduct your search queries but also how effective retrieval will be.</p>
<p>In the second part of this week’s lecture, we’re going to dig deeper and talk about some different search strategies and features you can use to make searching even more precise.</p>
<p>This is the end of this lecture on information representation within the information retrieval arena. Now you should proceed to the optional lecture that will teach you more about searching and different search strategies that you might employ to become better searchers.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="quarto-auto-generated-content">
<p><img src="images/ou.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="index_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="index_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="index_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="index_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="index_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="index_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="index_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"theme":"whiteboard"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: "separate-page",

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: true,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>